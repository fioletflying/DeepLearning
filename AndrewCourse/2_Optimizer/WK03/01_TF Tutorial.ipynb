{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF Tutorial\n",
    "\n",
    "### 基础模型\n",
    "\n",
    "以后需要用到的一些基础函数，其实跟之前的案例很像，大家在仔细看看。里面加入了tensorflow的一些函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tf_utils import load_dataset, random_mini_batches, convert_to_one_hot, predict\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    train_dataset = h5py.File('datasets/train_signs.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('datasets/test_signs.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "\n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "\n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n",
    "\n",
    "\n",
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "\n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
    "\n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "\n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "\n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "\n",
    "    return mini_batches\n",
    "\n",
    "\n",
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y\n",
    "\n",
    "\n",
    "def predict(X, parameters):\n",
    "\n",
    "    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n",
    "    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n",
    "    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n",
    "    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n",
    "    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n",
    "    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n",
    "\n",
    "    params = {\"W1\": W1,\n",
    "              \"b1\": b1,\n",
    "              \"W2\": W2,\n",
    "              \"b2\": b2,\n",
    "              \"W3\": W3,\n",
    "              \"b3\": b3}\n",
    "\n",
    "    x = tf.placeholder(\"float\", [12288, 1])\n",
    "\n",
    "    z3 = forward_propagation_for_predict(x, params)\n",
    "    p = tf.argmax(z3)\n",
    "\n",
    "    sess = tf.Session()\n",
    "    prediction = sess.run(p, feed_dict = {x: X})\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一个简单的例子\n",
    "\n",
    "#### tf 程序运行的步骤\n",
    "\n",
    "这里我来用tf计算一个损失函数：\n",
    "$loss = L(\\hat y,y)=(\\hat y^{(i)}-y^{(i)})^2$\n",
    "\n",
    "运行一个tf程序的基本步骤：\n",
    "- 创建张量Tensor（变量）\n",
    "- 创建节点操作，用来运算张量\n",
    "- 初始化张量\n",
    "上面的步骤，是用来创建一个计算图\n",
    "- 创建Session(会话)，用来运算op\n",
    "- 运行Session,计算op\n",
    "上面的步骤，是用来运行这张计算图\n",
    "\n",
    "具体的coding如下：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# 定义两个常量constant\n",
    "y_hat = tf.constant(36,name='y_hat')\n",
    "y = tf.constant(39,name=\"y\")\n",
    "\n",
    "# 定义一个变量，用来接收计算的值\n",
    "loss = tf.Variable((y-y_hat)**2,name='loss')\n",
    "\n",
    "# 用来初始化定义所有变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 创建一个Session,用来运行程序\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(sess.run(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 理解计算图与Session(会话)\n",
    "\n",
    "首先看如下例子：\n",
    "下面的例子中可以看出，c的结果并没有像我们想象的那样计算正确的结果，而是显示关于c的基本信息:\n",
    "- Mul:表示计算的节点\n",
    "- shape:表示tensor的size\n",
    "- dtype:表示tensor的类型\n",
    "\n",
    "这里仅仅是构建了一张计算图，并没有运行这张计算图\n",
    "只要通过Session构建会话，run()才能将计算开始运算起来。\n",
    "再次总结以下：\n",
    "- 初始化参数变量\n",
    "- 创建Session\n",
    "- 使用Session的run函数，完成相关的op操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_2:0\", shape=(), dtype=int32)\n",
      "Tensor(\"Mul_1:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 理解计算图\n",
    "a = tf.constant(2)\n",
    "b = tf.constant(10)\n",
    "print(a)\n",
    "c = tf.multiply(a,b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "# 运行计算图，Sesssion\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(c))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### placeholder占位符的概念\n",
    "\n",
    "通过占位符，我们可以将数据在使用的时候再指定。\n",
    "通过使用“feed 字典”来指定，具体函数：feed_dict\n",
    "一个简单的例子coding如下：\n",
    "需要说明的如下：\n",
    "\n",
    "- 定义一个占位符，里面并没有指定任何的数据\n",
    "- 这个占位符就是告诉我们，我们先留好一个位置，具体谁来坐，等到开会的时候再来定。\n",
    "- 在需要这个数据的时候，再使用使用feed_dict，组成的字典形式，来告诉tf来使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"x_1:0\", dtype=int64)\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# 定义一个占位符，里面并没有指定任何的数据\n",
    "x = tf.placeholder(tf.int64,name=\"x\")\n",
    "print(x)\n",
    "with tf.Session() as sess:\n",
    "    # 在使用的时候指定对应的数据\n",
    "    # 使用feed_dict，组成的字典形式\n",
    "    print(sess.run(2*x,feed_dict={x:3}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线性函数的表示\n",
    "\n",
    "下面我们正式来开始利用tf来对我们的基础函数的编程，首先是实现线性函数，也就是利用权重和偏置值计算Z.\n",
    "\n",
    "$\n",
    "Y = WX + b\n",
    "$\n",
    "\n",
    "我们需要用到的tf函数如下：\n",
    "- tf.matmul() :计算矩阵的乘法\n",
    "- tf.add() :计算加法\n",
    "- np.random.randn():初始化一个随机的值\n",
    "\n",
    "具体的coding如下：\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_function():\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    \n",
    "    # 创建tensor和计算图\n",
    "    X = tf.constant(np.random.randn(3,1),name=\"X\")\n",
    "    W = tf.constant(np.random.randn(4,3),name=\"W\")\n",
    "    b = tf.constant(np.random.randn(4,1),name=\"b\")\n",
    "    Y = tf.add(tf.matmul(W,X),b)\n",
    "    \n",
    "    # 创建会话并运行计算图\n",
    "    with tf.Session() as sess:\n",
    "        result =  sess.run(Y)\n",
    "        \n",
    "    return result\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result = [[-2.15657382]\n",
      " [ 2.95891446]\n",
      " [-1.08926781]\n",
      " [-0.84538042]]\n"
     ]
    }
   ],
   "source": [
    "print( \"result = \" + str(linear_function()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 个人觉得\n",
    "def linear_function():\n",
    "    \n",
    "    X = tf.placeholder(tf.float32,name=\"X\")\n",
    "    \n",
    "    W = tf.Variable(tf.float32,name=\"W\")\n",
    "    b = tf.Variable(tf.float32,name=\"b\")\n",
    "    \n",
    "    Y = tf.add(tf.matmul(W,X),b)\n",
    "    \n",
    "     \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算sigmoid激活函数\n",
    "\n",
    "这里我们将直接使用tf自带的sigmoid函数，tf.sigmoid(),需要定义的函数参数使用x,使用placeholder来接收传进来的参数。具体的步骤如下：\n",
    "\n",
    "- 定义tensor: placeholder\n",
    "- 使用tf.sigmoid(),构建op\n",
    "- 运行session:记得将对应的数据喂入对应的placeholder中\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \n",
    "    x = tf.placeholder(tf.float32,name=\"x\")\n",
    "    \n",
    "    sigmoid = tf.sigmoid(x)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        result = sess.run(sigmoid,feed_dict={x:z})\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simoid(1):0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"simoid(1):\" + str(sigmoid(0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算损失函数\n",
    "\n",
    "对于二分类的损失函数，我们可以定义如下：\n",
    "![](imgs/2.jpg)\n",
    "\n",
    "这里我们可以使用tf自带的函数来实现：\n",
    "`tf.nn.sigmoid_cross_entropy_with_logists(logits = ..., labels = ...)`\n",
    "\n",
    "其实该公式传入的参数只需要传入`z`它会自动计算`a`,实现的具体公式如下：\n",
    "![](imgs/3.jpg)\n",
    "\n",
    "具体coding如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(logits,labels):\n",
    "    \n",
    "    z = tf.placeholder(tf.float32,name=\"z\")\n",
    "    y = tf.placeholder(tf.float32,name=\"y\")\n",
    "    \n",
    "    cost = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        logits=z,\n",
    "        labels=y\n",
    "    )\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        cost = sess.run(cost,feed_dict={z:logits,y:labels})\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = [1.0053872  1.0366408  0.41385433 0.39956617]\n"
     ]
    }
   ],
   "source": [
    "logits = sigmoid(np.array([0.2,0.4,0.7,0.9]))\n",
    "cost = cost(logits, np.array([0,0,1,1]))\n",
    "print (\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot 编码\n",
    "\n",
    "就是将具体的数字转换成0，1编码，其过程如下:\n",
    "![](imgs/4.jpg)\n",
    "\n",
    "通过tf可以很方面调用其API来实现：\n",
    "`tf.one_hot(labels,depth,axis)`\n",
    "下面实例如下：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_matrix(labels,C):\n",
    "    \n",
    "    C = tf.constant(value=C,name=\"C\")\n",
    "    \n",
    "    one_hot_matrix = tf.one_hot(labels,C,axis=0)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        one_hot = sess.run(one_hot_matrix)\n",
    "        \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot = [[0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "labels = np.array([1,2,3,0,2,1])\n",
    "one_hot = one_hot_matrix(labels, C = 4)\n",
    "print (\"one_hot = \" + str(one_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化为0或者1\n",
    "\n",
    "可以直接使用\n",
    "`tf.ones` 或者 `tf.zeros` 这里需要我们传入的shape的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ones(shape):\n",
    "    \n",
    "    ones = tf.ones(shape)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        ones = sess.run(ones)\n",
    "        \n",
    "    return ones\n",
    "\n",
    "def zeros(shape):\n",
    "    \n",
    "    zeros = tf.zeros(shape)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        zeros = sess.run(zeros)\n",
    "        \n",
    "    return zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ones = [1. 1. 1.]\n",
      "zeros = [0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print (\"ones = \" + str(ones([3])))\n",
    "print (\"zeros = \" + str(zeros([3])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
