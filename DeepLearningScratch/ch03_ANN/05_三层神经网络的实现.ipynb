{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 层神经网络的实现\n",
    "\n",
    "通过前面几节的基础知识的介绍，我们对神经网络的组成有了一定的认识，我们这里就将演示一个完整的3层神经网络的实际演化的过程层。同时我们也将使用上一小节中，Numpy对于矩阵操作的技巧。\n",
    "\n",
    "先看看本节需要实现的神经网络的样子：\n",
    "\n",
    "![3层神经网络](imgs/10.jpg)\n",
    "\n",
    "- 输入为[x1,x2]\n",
    "- 第一层3个神经元\n",
    "- 第二层2个神经元\n",
    "- 输出层y1,y2\n",
    "\n",
    "### 表示符号的约定\n",
    "\n",
    "由于神经网络中符号既要表示出符号处在哪一层，又要表示在该层中的位置，所以这里我们的符号，稍微有点复杂，但是也不是很难。\n",
    "\n",
    "- 输出层的符号：$x1,x2$ 里面的[1,2,3...]表示输入的数组的序列号。\n",
    "- 权重$W_{12}^{(1)}$ \n",
    "    - (1): 表示第1层的权重，第几层的权重\n",
    "    - 12： 该权重连接的后一层和前一层的第几个神经元\n",
    "        - 1：表示后一层的第1一个神经元\n",
    "        - 2：表示前一层的第2一个神经元\n",
    "        \n",
    "![](imgs/11.jpg)\n",
    "\n",
    "- 隐藏层$a_1^{(1)}$\n",
    "    - 下标表示：在该层中的序列位置\n",
    "    - 上标表示：在第几层的位置\n",
    "    \n",
    "    \n",
    "### 信号的传递的过程\n",
    "\n",
    "#### 输入层传输到第一层信号量过程\n",
    "\n",
    "我们来看一下从输入层到第一层的某一神经元的信号传递过程。\n",
    "\n",
    "![信号传递](imgs/12.jpg)\n",
    "\n",
    "上图显示信号传递的过程，里面在输入层添加了一个1，用来进行偏置的数据输入。这里主要是为了方便将整个过程讲清楚而添加的，实际操作中，我们会直接加上b。\n",
    "\n",
    "其实所谓的信号传递，就是通过我们以前介绍的公式来实现，没有那么复杂。比如我们要计算，传递给该神经元的信号量为多少,具体公式如下：  \n",
    "$a_1^{(1)} = w_11^{(1)}x_1 + w_12^{(1)}x_2 + b_1^{(1)}  $\n",
    "\n",
    "上面第一层具体一个神经元的计算公式，我们如果使用矩阵的形式，就可以将整个的该层计算出来。  \n",
    "$A^{(1)}=XW^{(1)}+B^{(1)}$\n",
    "\n",
    "       \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n",
      "(2, 3)\n",
      "(3,)\n",
      "[0.6 1.3 2. ]\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 从输入层到第一层的信号传递过程\n",
    "import numpy as np\n",
    "\n",
    "# X 输入层，一维数组\n",
    "X = np.array([1,2])\n",
    "# W 连接输入层2，第一层神经元个数为3，所以构成（2，3）的矩阵\n",
    "W = np.array([[0.1,0.3,0.5],[0.2,0.4,0.6]])\n",
    "# B 是一个一维的数组，size是第一层神经元个数为3\n",
    "B = np.array([0.1,0.2,0.3])\n",
    "\n",
    "print(X.shape)\n",
    "print(W.shape)\n",
    "print(B.shape)\n",
    "\n",
    "# 信号传递到具体的神经元计算如下\n",
    "A1 = np.dot(X,W)+B\n",
    "\n",
    "print(A1)\n",
    "print(A1.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第一层激活的过程\n",
    "\n",
    "下面信号量已经传递过来了，我们需要利用激活来激活这个神经元。具体如下图：\n",
    "\n",
    "![](imgs/13.jpg)\n",
    "\n",
    "\n",
    "这里激活函数我们选用sigmoid函数。上图中的h()就是使用sigmoid函数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0/(np.exp(-x)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64565631 0.78583498 0.88079708]\n"
     ]
    }
   ],
   "source": [
    "Z1 = sigmoid(A1)\n",
    "print(Z1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第一层到第二层信号传递过程\n",
    "\n",
    "这里我们就可以参考上面的过程，使用的计算公式都是一样的：  \n",
    "$A^{(2)}=Z1W^{(2)}+B^{(2)}$  \n",
    "$Z2 = sigmoid(A^{(2)})$  \n",
    "具体的过程如下图：\n",
    "![](imgs/14.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "(2,)\n",
      "[0.84071466 1.1719435 ]\n",
      "(2,)\n",
      "[0.69861571 0.76349613]\n"
     ]
    }
   ],
   "source": [
    "# 第一层3个神经元，第二层2个神经元所以W2(3,2)\n",
    "W2 = np.array([[0.1,0.2],[0.3,0.4],[0.5,0.6]])\n",
    "# 第二层2个神经元，B2(2,)\n",
    "B2 = np.array([0.1,0.2])\n",
    "print(W2.shape)\n",
    "print(B2.shape)\n",
    "A2 = np.dot(Z1,W2) + B2\n",
    "print(A2)\n",
    "print(A2.shape)\n",
    "\n",
    "Z2 = sigmoid(A2)\n",
    "print(Z2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第二层到输出层信号传递过程\n",
    "\n",
    "这里我们要注意，关于输出层激活函数的选择，要根据实际的问题来选用适当的激活函数，比如：\n",
    "- 二分类问题可以选用：sigmoid\n",
    "- 多分类可以选用：softmax\n",
    "- 回归则可以选用这里的恒等，其实就是输出一个特定的值。\n",
    "\n",
    "这里为了统一就定义一个简单的恒等函数，其实没有什么意义。\n",
    "具体的过程如下图：\n",
    "![](imgs/15.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_fun(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "(2,)\n",
      "[0.39891041 0.6451216 ]\n"
     ]
    }
   ],
   "source": [
    "# 第二层2个神经元，输出层2个神经元所以W2(3,2)\n",
    "W3 = np.array([[0.1,0.2],[0.3,0.4]])\n",
    "B3 = np.array([0.1,0.2])\n",
    "print(W3.shape)\n",
    "A3 = np.dot(Z2,W3)+B3\n",
    "print(A3.shape)\n",
    "output = identity_fun(A3)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最好将上面的代码整合到一起，具体如下：\n",
    "先定义号网络的需要的参数，其实这个就是在定义网络的层数和神经元的个数。\n",
    "再定义一个信号传递的函数，信号前向传播函数。具体如下code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_network():\n",
    "    net={}\n",
    "    net['W1'] = np.array([[0.1,0.3,0.5],[0.2,0.4,0.6]])\n",
    "    net['W2'] = np.array([[0.1,0.2],[0.3,0.4],[0.5,0.6]]) \n",
    "    net['W3'] = np.array([[0.1,0.2],[0.3,0.4]])\n",
    "    net['B1'] = np.array([0.1,0.2,0.3])\n",
    "    net['B2'] = np.array([0.1,0.2])\n",
    "    net['B3'] = np.array([0.1,0.2])\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前向传播网络\n",
    "def forward(network,x):\n",
    "    W1,W2,W3 = network['W1'],network['W2'],network['W3']\n",
    "    b1,b2,b3 = network['B1'],network['B2'],network['B3']\n",
    "    \n",
    "    # 第一层\n",
    "    A1 = np.dot(x,W1)+b1\n",
    "    Z1 = sigmoid(A1)\n",
    "    #第二层\n",
    "    A2 = np.dot(Z1,W2)+b2\n",
    "    Z2 = sigmoid(A2)\n",
    "    #输出层\n",
    "    Z3 = np.dot(Z2,W3) + b3\n",
    "    y = identity_fun(Z3)\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3861894  0.62622355]\n"
     ]
    }
   ],
   "source": [
    "# 构建网络\n",
    "network = init_network()\n",
    "x = np.array([0.5,0.6])\n",
    "\n",
    "y = forward(network,x)\n",
    "print(y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
