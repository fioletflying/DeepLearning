{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多维数组的运算\n",
    "\n",
    "为了后面能够顺利实现神经网络的高效运算，这里要先了解一下多维数组的一些基本概念和运算。\n",
    "\n",
    "### 多维数组\n",
    "多维指的是一个数据需要表示的维度。\n",
    "一维数组：向量，一条线性，\n",
    "二维数组：矩阵，一个平面\n",
    "三维数组：立体，一个立体\n",
    "\n",
    "### 一维数组\n",
    "在Numpy中，可以使用如下函数来获得对数组数据的信息：\n",
    "- dtype:类型\n",
    "- ndim:数组的轴（维度）的个数,返回的是一个元组\n",
    "- size:数组元素的总数\n",
    "- itemsize:数组中每个元素的字节大小\n",
    "- data:该缓冲区包含数组的实际元素\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "1\n",
      "1\n",
      "(3,)\n",
      "int32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 只有一个中括号\n",
    "x = np.array([1,2,3])\n",
    "print(x)\n",
    "# 数组的维度\n",
    "print(np.ndim(x))\n",
    "print(x.ndim)\n",
    "# 数组的形状\n",
    "print(x.shape)\n",
    "# 数组的数据类型\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二维数组\n",
    "\n",
    "Numpy二维数组的数据组成的形式，是有两个中括号。\n",
    "- ndim 维度为2\n",
    "- 数据是由排和列组成的矩阵\n",
    "- shape(2,3),表示行数为2，列数为3.\n",
    "    - shape[0] :表示行数\n",
    "    - shape[1]:表示列数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "2\n",
      "(2, 3)\n",
      "int32\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1,2,3],[4,5,6]])\n",
    "print(x)\n",
    "# 数组的维度\n",
    "print(x.ndim)\n",
    "# 数组的形状\n",
    "print(x.shape)\n",
    "# 数组的数据类型\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 矩阵的乘法\n",
    "\n",
    "Numpy中的矩阵的乘法是利用如下的函数：\n",
    "- `np.dot(A,B)`\n",
    "- 矩阵的乘积也称为点积\n",
    "\n",
    "矩阵乘法的工作原理：\n",
    "- 矩阵的乘积是通过左边矩阵的行（横向）和右边矩阵的列（纵向）以对应元素的方式相乘后再求和而得到的\n",
    "- 运算的结果保存为新的多维数组的元素\n",
    "    - 矩阵A的第1行与矩阵B的第1列乘积的结果，就放到新矩阵的第1行和第1列\n",
    "    - 左边的矩阵决定结果的行号，右边的矩阵决定结果的列号\n",
    "    \n",
    "具体coding如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(3, 2)\n",
      "[[22 28]\n",
      " [49 64]]\n",
      "(2, 2)\n",
      "(3, 2)\n",
      "(2,)\n",
      "[23 53 83]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 矩阵的乘法\n",
    "A = np.array([[1,2,3],[4,5,6]])\n",
    "B = np.array([[1,2],[3,4],[5,6]])\n",
    "print(A.shape)\n",
    "print(B.shape)\n",
    "C = np.dot(A,B)\n",
    "print(C)\n",
    "print(C.shape)\n",
    "\n",
    "# 二维矩阵与一维矩阵的乘法\n",
    "A = np.array([[1,2],[3,4],[5,6]])\n",
    "B = np.array([7,8])\n",
    "\n",
    "print(A.shape)\n",
    "print(B.shape)\n",
    "\n",
    "C = np.dot(A,B)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不是任何矩阵都可以做乘法的，一条基本的原则是：\n",
    "- 矩阵的第 1 维和矩阵的第 0 维的元素个数一致得到新的矩阵shape(A.shape[0],B.shape[1])\n",
    "\n",
    "![矩阵乘法的原则](imgs/8.jpg)\n",
    "\n",
    "#### 神经网络的内积\n",
    "\n",
    "上面我们一起看了多维矩阵的内积的运算，其实我们我们实现的神经网络也就是这样一个过程。我们先来复习一下，之前是如何来计算神经网络的。\n",
    "\n",
    "以前我们只有一层而且神经元的个数也只有一个，所以用简单的矩阵乘法和调用了Nunpy中的sum函数来实现。其实这里也可以用矩阵的内积来实现。\n",
    "- w 需要转置成二维向量\n",
    "- 使用内积。\n",
    "\n",
    "```\n",
    "x = np.array([x1,x2])\n",
    "w = np.array([0.5,0.5])\n",
    "b = -0.6\n",
    "    \n",
    "result = np.sum(x*w)+b\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# 感知机的矩阵内积实现\n",
    "\n",
    "def AND(x1,x2):\n",
    "    x = np.array([x1,x2])\n",
    "    # 这里w 需要改成二维的向量\n",
    "    w = np.array([[0.5],[0.5]])\n",
    "    b = -0.6\n",
    "    # 利用矩阵内积\n",
    "    result = np.dot(x,w)+b\n",
    "    \n",
    "    if result >0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0  \n",
    "    \n",
    "print(AND(0,1))\n",
    "print(AND(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们再来看看神经网络的层的实现例子。与感知机相比，更加复杂。具体如下图的示例：\n",
    "![](imgs/9.jpg)\n",
    "\n",
    "x:[x1,x2]是一个一维数组\n",
    "w:[[w11,w21,w31]\n",
    "   [w12,w22,w32]]是一个矩阵\n",
    "   \n",
    "这样使用点积很方便就实现了对于Y的计算。具体如下coding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n",
      "(2, 3)\n",
      "[ 5 11 17]\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array([1,2])\n",
    "W = np.array([[1,3,5],[2,4,6]])\n",
    "\n",
    "print(X.shape)\n",
    "print(W.shape)\n",
    "\n",
    "Y = np.dot(X,W)\n",
    "print(Y)\n",
    "print(Y.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
