{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输出层的设计\n",
    "\n",
    "### 神经网络两个具体问题\n",
    "\n",
    "&emsp;上面一小节上我们在最后的输出层使用的是恒等函数，也就是直接将最后一层的信号量通过加权计算后的数据直接在输出层输出来。这里我们就要重点来看看输出层到底需要怎么来输出。  \n",
    "&emsp;一般神经网络输出层有两种分类，这个分类是根据实际网络需要解决的具体问题而定：\n",
    "- 分类问题：一般选用softmax函数\n",
    "    - 判断输入的数据是属于哪个类别，比如是猫还是狗\n",
    "- 回归问题：一般选用恒等函数\n",
    "    - 用来预测具体数值问题，比如预测温度，体重等具体数值\n",
    "    \n",
    "### 恒等函数和 softmax 函数\n",
    "\n",
    "#### 恒等函数\n",
    "&emsp;上面一小节上我们在最后的输出层使用的是恒等函数，也就是直接将最后一层的信号量通过加权计算后的数据直接在输出层输出来。所以这里就可以直接表示如下图：\n",
    "\n",
    "![恒等函数](imgs/16.jpg)\n",
    "\n",
    "#### softmax 函数\n",
    "\n",
    "&emsp;softmax函数其实没有那么神秘，其实就是对最后的值计算一个指数，然后将所有的输出层求和，在计算各个输出所占的比例。计算公式如下：  \n",
    "$y_k =\\frac{exp(a_k)}{\\sum^n_{i=1}{exp(a_i)}} $\n",
    "\n",
    "- $a_k$:表示第k个输出的输入信号\n",
    "- 分子:表示$a_k$的指数函数\n",
    "- 分母:表示所有信号的指数函数的和\n",
    "\n",
    "这里通过一个例子来理解,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.10517092 0.81873075 1.34985881]\n",
      "3.2737604787296326\n",
      "[0.33758454 0.25008878 0.41232669]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 倒数第二层的输入加权信号为\n",
    "a = np.array([0.1,-0.2,0.3])\n",
    "# 对输入信号进行指数函数计算\n",
    "z = np.exp(a)\n",
    "print(z)\n",
    "# 计算总和\n",
    "z_sum = np.sum(z)\n",
    "print(z_sum)\n",
    "#计算softmax值\n",
    "#其实就是计算对于输出所占的比例\n",
    "y = z/z_sum\n",
    "print(y)\n",
    "# y_sum这个值是1\n",
    "y_sum = np.sum(y)\n",
    "print(y_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax函数可以归纳如下\n",
    "def softmax(a):\n",
    "    exp_a = np.exp(a)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a/sum_exp_a\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### softmax函数需要注意的点\n",
    "\n",
    "&ensp;&ensp;上面我使用softmax来分类,里面有一个最大的特点就是使用指数函数.指数函数这里在数学计算中可能没有什么特别的地方,但是到了计算机就有不同了,因为计算机对于数据的大小表示是由范围限制的.比如:$e^{10}$与$e^{1000}$,计算机的表示是不同的.后者可能表示为无穷大，出现溢出的情况。\n",
    "\n",
    "&ensp;&ensp;为了让数据的输入在一个正常的范围,让计算能够能够正常显示,下面我们对这个公式做一个变换.这样即使输入的数据是一个比较大的值，我们也可让计算机正常的表示而且又不破坏数据的正确性。\n",
    "\n",
    "具体的公式如下：\n",
    "\n",
    "![](imgs/17.jpg)\n",
    "\n",
    "上面的公式利用以下的特性：\n",
    "- 分子分母同时乘以常数，结果不会改变\n",
    "- 利用指数函数和对数函数的特性\n",
    "最终想表达的意思就是：sofrmax函数中，加上（或者减去）\n",
    "某个常数并不会改变运算的结果。\n",
    "利用该特性，防止数据溢出，这里可以减去某个常数（通常是所有数据中的最大值）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan]\n",
      "[ -9   0 -20]\n",
      "[1.23394576e-04 9.99876603e-01 2.06089928e-09]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\python35\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "d:\\program files\\python35\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a= np.array([10001,10010,9990])\n",
    "print(np.exp(a)/np.sum(np.exp(a)))\n",
    "\n",
    "c = np.max(a)\n",
    "b= a-c\n",
    "print(b)\n",
    "print(np.exp(b)/np.sum(np.exp(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax 函数的改进\n",
    "\n",
    "def softmax(a):\n",
    "    c= np.max(a)\n",
    "    b = a - c # 防止溢出\n",
    "    exp_a = np.exp(b)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a/sum_exp_a\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### softmax 函数的特征\n",
    "\n",
    "从上面的实例中我们可以看出softmax有如下特征：\n",
    "- softmax值的总和是1\n",
    "- softmax输出的每个值其实就是该值输出的概率\n",
    "    -例如y[0] = 0.18, 就是第0个类别的概率为18%\n",
    "- 各个元素之间的大小关系也不会改变。这是因为指数函数（y = exp(x)）是单调递增函数\n",
    "- 神经网络只把输出值最大的神经元所对应的类别作为识别结果。\n",
    "\n",
    "由于这些因素才导致我们在分类经常在输出层采用softmax函数来处理。\n",
    "\n",
    "### 输出层的神经元数量设定\n",
    "\n",
    "输出层的神经元数量设定需要根据具体的情况来定，说的简单点就是我们需要分辨几类，就设定几个输出层。\n",
    "比如我们需要分辨：猫，狗，猪，羊，这里我们就需要设定4个输出\n",
    "再比如需要识别数字：0-9，这里我们就需要设定10个输出.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
