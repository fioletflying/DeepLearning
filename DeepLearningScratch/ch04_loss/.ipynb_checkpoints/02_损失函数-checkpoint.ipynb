{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数\n",
    "\n",
    "在我们利用数据来寻找最优参数的过程中,我们这里就需要思考,什么才叫最优参数呢? 如何来评价我们寻找到个参数是最优参数呢?\n",
    "\n",
    "这个时候我们的损失函数就出现了,通过损失函数计算的这个指标就可以对我们的模型作出一个合理判断,判断目前模型\"性能有多好\",\"误差有多大\". 通过这个指标再反向给该模型的参数调整提供一个方向.\n",
    "\n",
    "目前较为常见的两个损失函数:\n",
    "- 均方误差(mean squared error)\n",
    "- 交叉熵误差(cross entropy error)\n",
    "\n",
    "### 均方误差(mean squared error)\n",
    "\n",
    "均方误差(mean squared error)是我们最为常见的一种方法,具体函数如下:  \n",
    "\n",
    "$E = \\frac12 \\sum_k(y_k - t_k)^2$\n",
    "\n",
    "公式符号表示:\n",
    "- $y_k$ 表示模型的输出\n",
    "- $t_k$ 表示实际数据的值\n",
    "- $k$表示数据的维度,比如手写字符:10个元素,$k=10$\n",
    "\n",
    "所以这里的均方误差计算的是:神经网络的输出和正确解监督数据的各个元素之差的平方，再求总和\n",
    "\n",
    "例如:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 神经网络的输出 y 是 softmax 函数的输出。由于 softmax 函数的输出可以理解为概率\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "# 将正确解标签设为 1，其他均设为 0\n",
    "# 。将正确解标签表示为 1，其他标签表示为 0 的表示方法称为 one-hot 表示\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 均方误差\n",
    "def mean_squared_error(y,t):\n",
    "    return 0.5 * np.sum((y-t)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交叉熵误差（cross entropy error）\n",
    "\n",
    "其公式如下：  \n",
    "$E = - \\sum_kt_klogy_k$\n",
    "公式说明：\n",
    "- log:是以e为底的自然对数$log_e$\n",
    "- $y_k$:是神经网络的输出\n",
    "- $t_k$:是正确解的标签，用one-hot表示\n",
    "所以可以看出上面的公式只计算正确解的标签的输出的自然对数，因为其他非正确解的标签都是0.\n",
    "例如，0-9的字符表示为2的标签如下：\n",
    "[0,0,1,0,0,0,0,0,0,0],只有index = 2时为1，其他的为零，带入到公式中，就可以看到这样的场景，只计算$logy_2$\n",
    "\n",
    "下面来看看log的图像，\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\python35\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in log\n",
      "  \n",
      "d:\\program files\\python35\\lib\\site-packages\\ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b203354be0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x = np.arange(0,1,0.01)\n",
    "y = np.log(x)\n",
    "y2 = -np.log(x)\n",
    "\n",
    "#plt.plot(x,y)\n",
    "plt.plot(x,y2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过上面的图我们可以发现，为什么这个函数也适合做损失函数。因为当我们的预测结果越接近1的时候，loss值会变小。\n",
    "当我们的预测结果越接近0的时候，loss值会变大。这个正好和我们的需要预测方向吻合。\n",
    "所以现在交叉熵的损失函数可以实现如下：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y,t):\n",
    "    \"\"\"\n",
    "    y: 是预测值\n",
    "    t: 标签值\n",
    "    \"\"\"\n",
    "    delta = 1e-7 # 为了防止y=0的情况\n",
    "    return -np.sum(t*np.log(y+delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.510825457099338\n",
      "2.302584092994546\n"
     ]
    }
   ],
   "source": [
    "# 测试softmax的预测值：\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "\n",
    "print(cross_entropy_error(np.array(y),np.array(t)))\n",
    "\n",
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "print(cross_entropy_error(np.array(y),np.array(t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mini_batch 学习\n",
    "\n",
    "上面我们提到了两个不同的损失函数，而且我们这里也比较偏向于使用交叉熵损失函数作为未来机器学习模型的训练。这里我训练的目的就是为了是的损失函数最小。\n",
    "\n",
    "上面的损失函数都是针对单个训练数据设定的，这里我们由于机器学习都是大量的数据，我们需要对更多的数据来计算损失函数，这是我们就要计算所有的训练数据的loss值，作为学习指标。  \n",
    "所以我们的的损失函数应该定义如下：  \n",
    "$E = - \\frac1N\\sum_n\\sum_kt_{nk}logy_{nk}$\n",
    "\n",
    "- N：表示数据的个数\n",
    "- $t_{nk}$：表示第n个数据的第k个元素的标签数据值\n",
    "- 上面的公式计算的是一个平均的值\n",
    "\n",
    "这里有一个问题，如果将所有的数据作为损失值来计算，当数据量大的时候，这种方式会比较费时间，这里我们提出一种mini-batch的方案，就是从训练数据选择一小批量来进行计算。\n",
    "例如，手写数字识别的案例，从60000个样本随机选取100个数据。\n",
    "\n",
    "**np.random.choice(60000, 10)** \n",
    "从 0 到 59999 之间随机选择 10 个数字\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n",
      "60000\n",
      "[ 3970 47964 26932 58891  1320 30954 34316 33800 34669 21858]\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train,y_train),(x_test,y_test) = \\\n",
    "    load_mnist(normalize=True,one_hot_label=True)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "train_size = len(x_train)\n",
    "print(train_size)\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size,\n",
    "                               batch_size)\n",
    "print(batch_mask)\n",
    "x_batch = x_train[batch_mask]\n",
    "y_batch = y_train[batch_mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mini-batch 版交叉熵误差的实现\n",
    "\n",
    "上面哪个交叉熵的函数只针对单个的训练数据，这里我们需要处理batch个数据，所以函数如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y,t):\n",
    "    # 这里引入reshape变换\n",
    "    #为了方便计算batch_size的输入\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1,t.size)\n",
    "        y = y.reshape(1,y.size)\n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(t*np.log(y+1e-7))/batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 针对，当监督数据是标签形式（非 one-hot 表示）\n",
    "def cross_entropy_erros(y,t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1,t.size)\n",
    "        y = y.reshape(1,y.size)\n",
    "        \n",
    "    batch_size = y.shape[0]\n",
    "    # np.log( y[np.arange(batch_size), t])。np.arange (batch_size) 会生成一个从 0 到 batch_size-1 的数组。比如\n",
    "#当 batch_size 为 5 时，np.arange(batch_size) 会生成一个 NumPy 数组\n",
    "#[0, 1, 2, 3, 4]。因为 t 中标签是以 [2, 7, 0, 9, 4] 的形式存储的，所以\n",
    "#y[np.arange(batch_size), t=[y[0,2], y[1,7], y[2,0], y[3,9], y[4,4]]）\n",
    "    return -np.sum(np.log(y[np.arange(batch_size),t]\n",
    "                           + 1e-7))/batch_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
