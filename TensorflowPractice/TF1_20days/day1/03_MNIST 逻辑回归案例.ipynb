{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本示例完成一个简单的字符识别的训练，主要是通过逻辑回归模型来实现相关的模型建立。因为这里主要的完成一个分类问题，所以使用回归模型即可。\n",
    "\n",
    "数据的就是MNIST数据的导入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "WARNING:tensorflow:From <ipython-input-1-6aa100a1b03f>:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From D:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From D:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting D:/Study/python/jupyter/DeepLearning/DeepLearningScratch/dataset\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting D:/Study/python/jupyter/DeepLearning/DeepLearningScratch/dataset\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting D:/Study/python/jupyter/DeepLearning/DeepLearningScratch/dataset\\t10k-images-idx3-ubyte.gz\n",
      "Extracting D:/Study/python/jupyter/DeepLearning/DeepLearningScratch/dataset\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"D:/Study/python/jupyter/DeepLearning/DeepLearningScratch/dataset\",\\\n",
    "                                 one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数的定义\n",
    "learning_rate = 0.01\n",
    "training_epochs = 5\n",
    "batch_size = 16\n",
    "display_step =1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于tf.reduce_mean的理解，主要是用来对张量进行维度压缩计算，可以指定在不同的维度上来使用相应的计算，比如计算累加，平均值等等。\n",
    "\n",
    ">tf.reduce_mean 函数用于计算张量tensor沿着指定的数轴（tensor的某一维度）上的的平均值，主要用作降维或者计算tensor（图像）的平均值。\n",
    "\n",
    "函数定义：\n",
    ">reduce_mean(input_tensor,\n",
    "                axis=None,\n",
    "                keep_dims=False,\n",
    "                name=None,\n",
    "                reduction_indices=None)\n",
    "---\n",
    "\n",
    ">\n",
    "第一个参数input_tensor： 输入的待降维的tensor;\n",
    "第二个参数axis： 指定的轴，如果不指定，则计算所有元素的均值;\n",
    "第三个参数keep_dims：是否降维度，设置为True，输出的结果保持输入tensor的形状，设置为False，输出结果会降低维度;\n",
    "第四个参数name： 操作的名称;\n",
    "第五个参数 reduction_indices：在以前版本中用来指定轴，已弃用;\n",
    "\n",
    "下面是一个案例\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    " \n",
    "x = [[1,2,3],\n",
    "      [1,2,3]]\n",
    " \n",
    "xx = tf.cast(x,tf.float32)\n",
    " \n",
    "mean_all = tf.reduce_mean(xx, keep_dims=False)\n",
    "mean_0 = tf.reduce_mean(xx, axis=0, keep_dims=False)\n",
    "mean_1 = tf.reduce_mean(xx, axis=1, keep_dims=False)\n",
    " \n",
    " \n",
    "with tf.Session() as sess:\n",
    "    m_a,m_0,m_1 = sess.run([mean_all, mean_0, mean_1])\n",
    " \n",
    "print m_a    # output: 2.0\n",
    "print m_0    # output: [ 1.  2.  3.]\n",
    "print m_1    #output:  [ 2.  2.]\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "tf.reduce_sum ：计算tensor指定轴方向上的所有元素的累加和;\n",
    "tf.reduce_max  :  计算tensor指定轴方向上的各个元素的最大值;\n",
    "tf.reduce_all :  计算tensor指定轴方向上的各个元素的逻辑和（and运算）;\n",
    "tf.reduce_any:  计算tensor指定轴方向上的各个元素的逻辑或（or运算）;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n",
      "[[1. 2. 3.]]\n",
      "[1. 2. 3.]\n",
      "[[2.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    " \n",
    "x = [[1,2,3],\n",
    "      [1,2,3]]\n",
    " \n",
    "xx = tf.cast(x,tf.float32)\n",
    " \n",
    "mean_all = tf.reduce_mean(xx, keepdims=False)\n",
    "mean_0 = tf.reduce_mean(xx, axis=0, keepdims=True)\n",
    "mean_00 = tf.reduce_mean(xx, axis=0, keepdims=False)\n",
    "mean_1 = tf.reduce_mean(xx, axis=1, keepdims=True)\n",
    " \n",
    " \n",
    "with tf.Session() as sess:\n",
    "    m_a,m_0,m_00,m_1 = sess.run([mean_all, mean_0,mean_00, mean_1])\n",
    "\n",
    "print(m_a)   # output: 2.0\n",
    "print(m_0)    # output: [ 1.  2.  3.]\n",
    "print(m_00)    # output: [ 1.  2.  3.]\n",
    "print(m_1 )   #output:  [ 2.  2.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入数据定义\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "#定义模型的权重参数\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# 构建模型，输出是利用softmax进行分类\n",
    "pred = tf.nn.softmax(tf.matmul(x,W)+b)\n",
    "\n",
    "# 利用cross entropy来定义损失函数\n",
    "cost = tf.reduce_mean(-tf.reduce_mean(y*tf.log(pred),\\\n",
    "                                     reduction_indices=1))\n",
    "#定义优化器，使用梯度下降法\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate) \\\n",
    "            .minimize(cost)\n",
    "\n",
    "# 参数初始化\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.cast()函数的作用是执行 tensorflow 中张量数据类型转换，比如读入的图片如果是int8类型的，一般在要在训练前把图像的数据格式转换为float32\n",
    "\n",
    ">cast(x, dtype, name=None)\n",
    "第一个参数 x:   待转换的数据（张量）\n",
    "第二个参数 dtype： 目标数据类型\n",
    "第三个参数 name： 可选参数，定义操作的名称\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    " \n",
    "t1 = tf.Variable([1,2,3,4,5])\n",
    "t2 = tf.cast(t1,dtype=tf.float32)\n",
    " \n",
    "print 't1: {}'.format(t1)\n",
    "print 't2: {}'.format(t2)\n",
    " \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(t2)\n",
    "    print t2.eval()\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "tf.argmax就是返回最大的那个数值所在的下标。\n",
    "\n",
    ">tf.argmax(input_tensor, axis=0)\n",
    "input_tensor，输入张量\n",
    "axis，指定维度，默认为0。二维情况下，若为0，则返回列数据最大值索引；若为1，则返回行数据最大值索引\n",
    "\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "X = tf.constant([[1, 2, 3], \n",
    "                 [2, 3, 4], \n",
    "                 [5, 4, 3], \n",
    "                 [8, 7, 2]], dtype=tf.float32)\n",
    "row_max_index = tf.argmax(X)               # 默认 0 维度，列最大值索引\n",
    "col_max_index = tf.argmax(X, axis=1)       # axis=1 或 1，行最大值索引\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print('列最大值索引：', sess.run(row_max_index))\n",
    "    print('行最大值索引：', sess.run(col_max_index))\n",
    "```\n",
    "\n",
    ">列最大值索引： [3 3 1]\n",
    "行最大值索引： [2 2 0 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with tf.Session() as sess:\n",
    "\tprint(accuracy.eval({x:mnist.test.images,y_: mnist.test.labels}))\n",
    "其效果和下面的代码是等价的：\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\tprint(sess.run(accuracy, {x:mnist.test.images,y_: mnist.test.labels}))\n",
    "\n",
    "但是要注意的是，eval()只能用于tf.Tensor类对象，也就是有输出的Operation。对于没有输出的Operation, 可以用.run()或者Session.run()。Session.run()没有这个限制。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 cost= 0.1384540504499823\n",
      "Epoch 2 cost= 0.08025390097526207\n",
      "Epoch 3 cost= 0.0650125704478102\n",
      "Epoch 4 cost= 0.05760409507996948\n",
      "Epoch 5 cost= 0.05314870741449189\n",
      "Epoch 6 cost= 0.05006595262198132\n",
      "Epoch 7 cost= 0.0477973668445047\n",
      "Epoch 8 cost= 0.04602712572595355\n",
      "Epoch 9 cost= 0.04460666821155881\n",
      "Epoch 10 cost= 0.04341231500835605\n",
      "training finished!!!!\n",
      "Accuracy: 0.8656667\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    #初始化参数\n",
    "    sess.run(init)\n",
    "    \n",
    "    #开始模型训练\n",
    "    for epoch in range(training_epochs):\n",
    "        # loss值\n",
    "        avg_cost = 0.\n",
    "        # 计算一个epoch需要输入几批数据\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # 将每批数据放入到模型中进行训练\n",
    "        for i in range(total_batch):\n",
    "            # 生成每次训练的数据\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            # 训练数据并计算loss值 \n",
    "            _,c = sess.run([optimizer,cost],\\\n",
    "                           feed_dict={x:batch_xs,y:batch_ys})\n",
    "            # 计算平均loss值\n",
    "            avg_cost += c / total_batch\n",
    "        \n",
    "        if (epoch + 1)%display_step == 0:\n",
    "            print(\"Epoch\",(epoch+1),\"cost=\",avg_cost)\n",
    "            \n",
    "    print(\"training finished!!!!\")\n",
    "      \n",
    "    correct_prediction = tf.equal(tf.argmax(pred,1),\\\n",
    "                                  tf.argmax(y,1))\n",
    "    #测试模型\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,\\\n",
    "                                      tf.float32))\n",
    "    # 计算精度\n",
    "    print(\"Accuracy:\",accuracy.eval({x:mnist.test.images[:3000],\\\n",
    "                                     y:mnist.test.labels[:3000]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5.3 64-bit",
   "language": "python",
   "name": "python35364bit3bacbdcc991d440db80818de2ad5e2b5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
