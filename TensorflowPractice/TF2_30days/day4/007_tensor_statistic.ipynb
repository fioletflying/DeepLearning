{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('tf2': conda)",
   "metadata": {
    "interpreter": {
     "hash": "e17394781024da1f0ed279aab7c6165e80e3acfd2491de02c017c43da5039587"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## 张量常用的数据统计\n",
    "\n",
    "比如统计最值，最值的位置，均值，范数等信息。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 向量范数\n",
    "向量范数(Vector Norm)表征向量\"长度\"的一种度量方法。常见的范数有：L1,L2,无穷大范数：例如向量的范数定义\n",
    "- L1 范数：向量所有元素的绝对值之和\n",
    "- L2 范数：向量所有元素的平方和，在开根号\n",
    "- inf 范数：向量所以元素绝对值的最大值\n",
    "\n",
    "利用tf.norm(x,ord)来求解：\n",
    "- ord =1 ：表示L1\n",
    "- ord = 2: L2 \n",
    "- ord = np.inf 表示最大值"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(4.0, shape=(), dtype=float32)\ntf.Tensor(2.0, shape=(), dtype=float32)\ntf.Tensor(1.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.ones([2,2])\n",
    "print(tf.norm(x,ord=1))\n",
    "print(tf.norm(x,ord=2))\n",
    "print(tf.norm(x,ord=np.inf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor([2. 2. 2.], shape=(3,), dtype=float32)\ntf.Tensor([1.4142135 1.4142135 1.4142135], shape=(3,), dtype=float32)\ntf.Tensor([1.7320508 1.7320508], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#指定轴上范数\n",
    "x = tf.ones([2,3])\n",
    "# 行的方向\n",
    "print(tf.norm(x,ord=1,axis=0))\n",
    "print(tf.norm(x,ord=2,axis=0))\n",
    "# 列的方向\n",
    "print(tf.norm(x,ord=2,axis=1))"
   ]
  },
  {
   "source": [
    "### 查找最值，均值，和以及最值的索引号\n",
    "- tf.reduce_max\n",
    "- tf.reduce_min\n",
    "- tf.reduce_mean\n",
    "- tf.reduce_sum\n",
    "- tf.argmax\n",
    "- tf.argmin\n",
    "\n",
    ">参数：\n",
    "- 第一个参数input_tensor： 输入的待降维的tensor;\n",
    "- 第二个参数axis： 指定的轴方向，如果不指定，则计算所有元素;\n",
    "- 第三个参数keep_dims：是否降维度，设置为True，输出的结果保持输入tensor的形状，设置为False，输出结果会降低维度;\n",
    "\n",
    "\n",
    "例如 shape[4,10], 记录的时候样本个数为4，10个类别的概率，需要找出每个样本的最大概率的值。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor([0.90580153 0.935712   0.9590367  0.94939566], shape=(4,), dtype=float32)\ntf.Tensor([0.12353003 0.06850481 0.03555584 0.26242328], shape=(4,), dtype=float32)\ntf.Tensor([0.5966229 0.5580625 0.508815  0.4725522], shape=(4,), dtype=float32)\ntf.Tensor([5.966229 5.580625 5.08815  4.725522], shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.random.uniform(shape=[4,10],minval=0,maxval=1,dtype=tf.float32)\n",
    "# 关于指定轴的理解：这里要求每一行中列元素的最大值，所以设置为列的方向\n",
    "print(tf.reduce_max(x,axis=1))\n",
    "print(tf.reduce_min(x,axis=1))\n",
    "print(tf.reduce_mean(x,axis=1))\n",
    "print(tf.reduce_sum(x,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=0.99992895>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.020911574>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.5184097>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=20.73639>)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# 不指定轴，则计算所有的元素的最值\n",
    "x = tf.random.uniform(shape=[4,10],minval=0,maxval=1,dtype=tf.float32)\n",
    "tf.reduce_max(x),tf.reduce_min(x),tf.reduce_mean(x),tf.reduce_sum(x)"
   ]
  },
  {
   "source": [
    "一个实际的计算关于损失值的过程，就需要使用上面的那些API来计算。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor([2.7964349 0.8372906 1.47877   1.5083137], shape=(4,), dtype=float32)\n样本误差： tf.Tensor([2.7964349 0.8372906 1.47877   1.5083137], shape=(4,), dtype=float32)\n总的均值误差： tf.Tensor(1.6552023, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "out = tf.random.normal([4,10])\n",
    "y = tf.constant([1,2,2,0])\n",
    "y = tf.one_hot(y,depth=10)\n",
    "# 计算每个样本的误差：均方差\n",
    "loss = tf.keras.losses.mse(y,out)\n",
    "mse = tf.reduce_mean(tf.square(out-y),axis=1)\n",
    "print(mse)\n",
    "print(\"样本误差：\",loss)\n",
    "# 计算总的评价误差\n",
    "loss = tf.reduce_mean(loss)\n",
    "print(\"总的均值误差：\",loss)"
   ]
  },
  {
   "source": [
    "### 最值索引号的获取\n",
    "\n",
    "-  tf.argmax(x, axis)\n",
    "-  tf.argmin(x, axis)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n[[0.31100145 0.10704491 0.02488793 0.01039608 0.18288529 0.11658079\n  0.03200262 0.06312642 0.06114587 0.09092861]\n [0.2951885  0.03986979 0.05252219 0.0377373  0.1492606  0.04129728\n  0.12838507 0.08179147 0.15033846 0.02360938]], shape=(2, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "out = tf.random.normal([2,10])\n",
    "# 转换成概率值\n",
    "out = tf.nn.softmax(out,axis=1)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor([0 0], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# 获得最大值的索引的位置\n",
    "pred = tf.argmax(out,axis=1)\n",
    "print(pred)\n"
   ]
  },
  {
   "source": [
    "### tensor的比较\n",
    "\n",
    "可以想象一个应用场景，就是用来统计分类任务的准确率的时候，需要将预测值与真实标签进行比较。\n",
    "- tf.equal(a,b)\n",
    "- tf.math.equal(a,b)\n",
    "\n",
    "返回值是True和False\n",
    "\n",
    "还有其他的比较函数\n",
    "tf.math.greater  𝑎 > 𝑏  \n",
    "tf.math.less  𝑎 < 𝑏  \n",
    "tf.math.greater_equal  𝑎 ≥ 𝑏  \n",
    "tf.math.less_equal  𝑎 ≤ 𝑏  \n",
    "tf.math.not_equal  𝑎 ≠ 𝑏  \n",
    "tf.math.is_nan  𝑎 = nan"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n[5 7 2 3 5 5 0 6 0 6 0 9 4 9 3 2 0 0 8 0 6 9 6 9 8 3 9 9 5 0 6 7 0 3 4 7 4\n 0 6 3 1 6 5 4 1 5 1 2 4 2 0 5 4 1 8 5 7 3 7 0 8 1 6 9 2 5 1 4 8 7 1 3 8 4\n 6 1 5 4 0 3 3 8 4 6 5 8 0 6 0 5 7 6 0 9 5 1 7 9 5 9], shape=(100,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# 模拟生成预测值\n",
    "out = tf.random.normal([100,10])\n",
    "out = tf.nn.softmax(out,axis=1)\n",
    "\n",
    "pred = tf.argmax(out,axis=1)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n[1 3 4 2 6 6 8 8 9 9 7 5 5 2 3 4 2 1 1 1 1 5 5 0 5 3 2 7 9 9 2 1 2 1 0 2 7\n 9 5 8 1 8 0 1 8 7 0 0 7 6 8 6 2 9 0 8 4 4 9 5 1 1 6 2 0 5 8 1 3 3 9 7 7 5\n 8 4 9 5 8 2 8 3 6 8 2 8 6 8 0 0 9 3 2 6 4 8 9 7 4 1], shape=(100,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "y = tf.random.uniform([100],dtype=tf.int64,maxval=10)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n[False False False False False False False False False False False False\n False False  True False False False False False False False False False\n False  True False False False False False False False False False False\n False False False False  True False False False False False False False\n False False False False False False False False False False False False\n False  True  True False False  True False False False False False False\n False False False False False False False False False False False False\n False  True False False  True False False False False False False False\n False False False False], shape=(100,), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "# 使用tf.equal来获得比较的结果，返回值是True和False\n",
    "out = tf.equal(pred,y)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(0.08, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "out = tf.cast(out,dtype =tf.float32)\n",
    "corret = tf.reduce_sum(out)/y.shape[0]\n",
    "print(corret)"
   ]
  }
 ]
}