{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3612jvsc74a57bd0e17394781024da1f0ed279aab7c6165e80e3acfd2491de02c017c43da5039587",
   "display_name": "Python 3.6.12 64-bit ('tf2': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### CNN \n",
    "\n",
    "#### 自定义权值\n",
    "\n",
    "\n",
    "> conv2d: (input, filters, strides, padding, data_format=\"NHWC\", dilations=None, name=None)\n",
    "Args:\n",
    "  - input: A Tensor. Must be one of the following types:\n",
    "   \n",
    "  - filters: A Tensor. Must have the same type as input.\n",
    "    A 4-D tensor of shape [filter_height, filter_width, in_channels, out_channels\\]\n",
    "  - strides: An int or list of ints that has length 1, 2 or 4.\n",
    "  - padding: Either the string \"SAME\" or \"VALID\" 或者[[0, 0\\], [pad_top, pad_bottom\\], [pad_left, pad_right\\], [0, 0\\]\\]\n",
    "  - data_format: An optional string from: \"NHWC\", \"NCHW\"\n",
    "  - dilations: An int or list of ints that has length 1, 2 or 4,\n",
    "  - name\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2, 3, 3, 4)\n"
     ]
    }
   ],
   "source": [
    "# batch:2, w:5,h:5,通道c：3\n",
    "x = tf.random.normal([2,5,5,3])\n",
    "# 创建卷积核[k,k,Cin,Cout] 创建w卷积和张量，4 个大小 3*3的卷积核\n",
    "# 这里的Cin需要与输入的x的通道数一样\n",
    "w = tf.random.normal([3,3,3,4])\n",
    "\n",
    "# 开始做卷积运算，步长stride=1,填充padding的数量为0\n",
    "out = tf.nn.conv2d(x,2,strides=1,padding='VALID')\n",
    "# out = tf.nn.conv2d(x,w,strides=1,padding=[[0,0],[0,0],[0,0],[0,0]])\n",
    "\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2, 5, 5, 4)\n"
     ]
    }
   ],
   "source": [
    "# batch:2, w:5,h:5,通道c：3\n",
    "x = tf.random.normal([2,5,5,3])\n",
    "# 创建卷积核[k,k,Cin,Cout] 创建w卷积和张量，4 个大小 3*3的卷积核\n",
    "# 这里的Cin需要与输入的x的通道数一样\n",
    "w = tf.random.normal([3,3,3,4])\n",
    "\n",
    "# 开始做卷积运算，步长stride=1,填充padding：上下左右都填充一行或者一列\n",
    "out = tf.nn.conv2d(x,w,strides=1,padding='SAME')\n",
    "# out = tf.nn.conv2d(x,w,strides=1,padding=[[0,0],[1,1],[1,1],[0,0]])\n",
    "\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2, 3, 3, 4)\n"
     ]
    }
   ],
   "source": [
    "# strides 会使得输入w,h 减少s倍\n",
    "# batch:2, w:5,h:5,通道c：3\n",
    "x = tf.random.normal([2,5,5,3])\n",
    "# 创建卷积核[k,k,Cin,Cout] 创建w卷积和张量，4 个大小 3*3的卷积核\n",
    "# 这里的Cin需要与输入的x的通道数一样\n",
    "w = tf.random.normal([3,3,3,4])\n",
    "\n",
    "# 开始做卷积运算，步长stride=2,填充padding：上下左右都填充一行或者一列\n",
    "out = tf.nn.conv2d(x,w,strides=2,padding='SAME')\n",
    "# out = tf.nn.conv2d(x,w,strides=1,padding=[[0,0],[1,1],[1,1],[0,0]])\n",
    "\n",
    "print(out.shape)"
   ]
  },
  {
   "source": [
    "tf.nn.conv2d 函数是没有实现偏置向量计算的，添加偏置只需要手动累加偏置张量即可。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要自己添加偏置值b\n",
    "\n",
    "b = tf.zeros([4])\n",
    "\n",
    "# 完成CNN之后需要添加偏置向量\n",
    "out =out+b"
   ]
  },
  {
   "source": [
    "### 卷积层类\n",
    "\n",
    "一个小tip: TF中如果首字母是大写表示类，如果首字母小写表示函数。\n",
    "\n",
    "使用类创建卷积层的好处：\n",
    "- 自动创建权值和偏置向量\n",
    "- 使用方便简单\n",
    "缺点就是灵活性偏低。\n",
    "\n",
    ">tf.keras.layers.Conv2D(filters,kernel_size,stides,padding,...)\n",
    "- filters:卷积核的数量\n",
    "- kernel_size：卷积核的大小：1，3，5，7...,如果卷积核的高宽不等，可以设计为tuple(Kh,Kw)\n",
    "- strides: 步长,步长的行列方向不等(Sh,Sw)\n",
    "- padding:'SAMW','VALID'"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2, 5, 5, 3)\n"
     ]
    }
   ],
   "source": [
    "x = tf.random.normal([2,5,5,3])\n",
    "layer = tf.keras.layers.Conv2D(4,kernel_size=3,strides=1,padding='SAME')\n",
    "# 调用__call__方法实现前向计算\n",
    "out = layer(x)\n",
    "print(x.shape)\n"
   ]
  },
  {
   "source": [
    "查看卷积核层中的W和b的值，在Conv2D中可以通过类的成员获得：\n",
    "- trainable_variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[<tf.Variable 'conv2d_1/kernel:0' shape=(3, 3, 3, 4) dtype=float32, numpy=\narray([[[[-0.00698531, -0.18152471,  0.20659754, -0.18127558],\n         [ 0.11066368,  0.1381051 , -0.12240578,  0.034143  ],\n         [-0.23642763,  0.05449861, -0.18418983, -0.30749518]],\n\n        [[-0.05759403,  0.04076633, -0.28257173, -0.02127391],\n         [-0.03639874,  0.17931798,  0.06684721, -0.11598556],\n         [ 0.19734183, -0.09807713,  0.08605251,  0.1778504 ]],\n\n        [[ 0.03840971, -0.08091767,  0.00733671, -0.22630328],\n         [ 0.20350131,  0.02513242, -0.15209588,  0.29834434],\n         [ 0.1666157 , -0.08778393,  0.24443355,  0.07791278]]],\n\n\n       [[[ 0.13810453, -0.30625686, -0.15261519, -0.2130385 ],\n         [ 0.03435674,  0.15389574, -0.28058895,  0.22830829],\n         [ 0.20459357,  0.02564237,  0.09563702, -0.13527568]],\n\n        [[ 0.24052313, -0.2935648 ,  0.05696899,  0.06041735],\n         [-0.07898553, -0.23838118,  0.16071793, -0.09439944],\n         [ 0.12513044,  0.29106268, -0.19839229, -0.08298866]],\n\n        [[ 0.03829145, -0.25919083, -0.08018646, -0.10898781],\n         [-0.24541858, -0.02242976,  0.06862897,  0.07554746],\n         [ 0.23690274, -0.01942116, -0.22425732,  0.1201947 ]]],\n\n\n       [[[-0.2608196 ,  0.03415257,  0.21620467, -0.27523157],\n         [ 0.16883728,  0.19390705,  0.2714046 ,  0.19607821],\n         [ 0.24653646, -0.04176357, -0.29920018, -0.09028918]],\n\n        [[-0.02891511,  0.25292668, -0.07378955, -0.0908073 ],\n         [ 0.10301045, -0.29813442, -0.20560583, -0.01501337],\n         [-0.19752915, -0.27880934,  0.22051015, -0.06156522]],\n\n        [[ 0.19342574,  0.00266308,  0.29584667,  0.27266082],\n         [-0.29418036, -0.05998485,  0.08779395, -0.06800488],\n         [-0.14313208, -0.20644963,  0.10471046, -0.01992482]]]],\n      dtype=float32)>, <tf.Variable 'conv2d_1/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "# 查看卷积核层中的W和b的值\n",
    "print(layer.trainable_variables)"
   ]
  }
 ]
}