{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## 过拟合与欠拟合\n",
    "\n",
    "- 过拟合：就是模型的只对训练的数据敏感，对于其他未见的样本表现不好，模型泛化能力较弱；\n",
    "- 欠拟合：模型对训练集和未见过的数据表现都差\n",
    "\n",
    "![](imgs/01.png)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 数据集的划分\n",
    "\n",
    "模型中三种数据类型：\n",
    "- 训练集：用来训练模型的数据\n",
    "- 验证集：在训练的过程中用来测试训练模型的精度，也是可以是训练集的一部分\n",
    "- 测试集：用来测试模型，不会放到训练集中，用来检验模型的泛化能力\n",
    "\n",
    "验证集的作用：\n",
    "- 根据验证集的性能表现来调整学习率、权值衰减系数\n",
    "- 根据验证集的性能表现来重新调整网络拓扑结构\n",
    "- 根据验证集的性能表现判断是否过拟合和欠拟合\n",
    "\n",
    "验证集在模型中使用方式：\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets,layers,optimizers,Sequential,metrics\n",
    "\n",
    "def preprocess(x,y):\n",
    "    x = tf.cast(x,dtype=tf.float32)/255.\n",
    "    x =tf.reshape(x,[28*28])\n",
    "    y =tf.cast(y,dtype=tf.int32)\n",
    "    y = tf.one_hot(y,depth=10)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "datase: (60000, 28, 28) (60000,) 0 255 0 9\n"
     ]
    }
   ],
   "source": [
    "# 创建训练数据\n",
    "batch_size = 128\n",
    "(x,y),(x_val,y_val) = datasets.mnist.load_data()\n",
    "print('datase:',x.shape,y.shape,x.min(),x.max(),y.min(),y.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(28, 28) ()\n",
      "(128, 784) (128, 10)\n"
     ]
    }
   ],
   "source": [
    "db = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "# 变换前\n",
    "sample = next(iter(db))\n",
    "print(sample[0].shape,sample[1].shape)\n",
    "\n",
    "db = db.map(preprocess).shuffle(60000).batch(batch_size)\n",
    "\n",
    "# 变换后\n",
    "sample2 = next(iter(db))\n",
    "print(sample2[0].shape,sample2[1].shape)\n",
    "\n",
    "db_val = tf.data.Dataset.from_tensor_slices((x_val,y_val))\n",
    "db_val = db_val.map(preprocess).batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_5 (Dense)              (None, 256)               200960    \n_________________________________________________________________\ndense_6 (Dense)              (None, 128)               32896     \n_________________________________________________________________\ndense_7 (Dense)              (None, 64)                8256      \n_________________________________________________________________\ndense_8 (Dense)              (None, 32)                2080      \n_________________________________________________________________\ndense_9 (Dense)              (None, 10)                330       \n=================================================================\nTotal params: 244,522\nTrainable params: 244,522\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network = Sequential([layers.Dense(256,activation='relu'),layers.Dense(128,activation='relu'),layers.Dense(64,activation='relu'),layers.Dense(32,activation='relu'),layers.Dense(10,activation='relu')])\n",
    "\n",
    "network.build(input_shape=(None,28*28))\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer=optimizers.Adam(lr=0.01),loss=tf.losses.CategoricalCrossentropy(from_logits=True),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.2997 - accuracy: 0.9098\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1388 - accuracy: 0.9618 - val_loss: 0.1613 - val_accuracy: 0.9536\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.1124 - accuracy: 0.9687\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1012 - accuracy: 0.9722 - val_loss: 0.1074 - val_accuracy: 0.9709\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0835 - accuracy: 0.9776\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18796cb6390>"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# fit 里面可以设置验证集\n",
    "# 一般\n",
    "network.fit(db,epochs=5,validation_data=db_val,validation_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "79/79 [==============================] - 1s 8ms/step - loss: 0.1402 - accuracy: 0.9634\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.14019764959812164, 0.9634000062942505]"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# 利用验证集来测试模型的准确性\n",
    "network.evaluate(db_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7\n 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9\n 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6 9 6 0 5 4 9 9 2 1 9 4 8\n 7 3 9 7 4 4 4 9 2 5 4 7 6 7 4 0 5], shape=(128,), dtype=int64)\ntf.Tensor(\n[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7\n 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9\n 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6 9 6 0 5 4 9 9 2 1 9 4 8\n 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5], shape=(128,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "sample = next(iter(db_val))\n",
    "x = sample[0]\n",
    "y = sample[1]\n",
    "\n",
    "pred = network.predict(x)\n",
    "\n",
    "y = tf.argmax(y,axis=1)\n",
    "pred = tf.argmax(pred,axis=1)\n",
    "\n",
    "print(pred)\n",
    "print(y)"
   ]
  },
  {
   "source": [
    "### 验证集的使用方式\n",
    "\n",
    "- 将数据集分割成三份\n",
    "    - train\n",
    "    - validation\n",
    "    - test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "datasets (60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# 例如上面的数据创建\n",
    "(x,y),(x_test,y_test) = datasets.mnist.load_data()\n",
    "print('datasets',x.shape,y.shape,x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再继续分割训练集成两份\n",
    "idx = tf.range(x.shape[0])\n",
    "idx = tf.random.shuffle(idx)\n",
    "\n",
    "# 创建训练集\n",
    "x_train,y_train = tf.gather(x,idx[:50000]),tf.gather(y,idx[:50000])\n",
    "# 创建验证集\n",
    "x_val,y_val = tf.gather(x,idx[50000:]),tf.gather(y,idx[50000:])\n",
    "\n",
    "db_train = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
    "db_train = db_train.map(preprocess).shuffle(50000).batch(batch_size)\n",
    "\n",
    "db_val = tf.data.Dataset.from_tensor_slices((x_val,y_val))\n",
    "db_val = db_val.map(preprocess).shuffle(10000).batch(batch_size)\n",
    "\n",
    "db_test = tf.data.Dataset.from_tensor_slices((x_test,y_test))\n",
    "db_test = db_test.map(preprocess).batch(batch_size)"
   ]
  }
 ]
}