{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor 简介\n",
    "\n",
    "#### tensor 创建\n",
    "用range函数创建一个行向量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  1  2  3  4  5  6  7  8  9 10 11], shape=(12,), dtype=int32)\n",
      "(12,)\n",
      "tf.Tensor(\n",
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]], shape=(3, 4), dtype=int32)\n",
      "(3, 4)\n",
      "tf.Tensor(\n",
      "[[[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]], shape=(2, 3, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]], shape=(3, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[2 1 4 3]\n",
      " [1 2 3 4]\n",
      " [4 3 2 1]], shape=(3, 4), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 5.0117981e-01 -1.8315295e+00  4.5560722e-04  1.0054147e+00]\n",
      " [-2.8371340e-01  9.5737427e-01 -7.0242584e-01 -9.0721762e-01]\n",
      " [ 2.7851656e-01  2.4362369e-01 -1.4869552e+00 -8.5668242e-01]], shape=(3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#用range函数创建一个行向量\n",
    "x = tf.constant(range(12))\n",
    "print(x)\n",
    "print(x.shape)\n",
    "# reshape函数把行向量x的形状改为(3, 4)\n",
    "#x =tf.reshape(x,(3,4))\n",
    "# 这里的-1是能够通过元素个数和其他维度的大小推断出来的\n",
    "x =tf.reshape(x,(-1,4))\n",
    "print(x)\n",
    "print(x.shape)\n",
    "\n",
    "# 创建一个各元素为0，形状为(2, 3, 4)的张量\n",
    "y = tf.zeros((2,3,4))\n",
    "print(y)\n",
    "\n",
    "# 可以创建各元素为1的张量\n",
    "z = tf.ones((3,4))\n",
    "print(z)\n",
    "\n",
    "#通过Python的列表（list）指定需要创建的tensor中每个元素的值\n",
    "m = tf.constant([[2,1,4,3],[1,2,3,4],[4,3,2,1]])\n",
    "print(m)\n",
    "\n",
    "#随机生成tensor中每个元素的值\n",
    "n = tf.random.normal(shape=[3,4], mean=0, stddev=1)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensor 运算\n",
    "\n",
    "按元素加减乘除法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[3 2 8 4]\n",
      " [2 4 6 8]\n",
      " [7 7 5 3]], shape=(3, 4), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 1  0  0  2]\n",
      " [ 0  0  0  0]\n",
      " [ 1 -1 -1 -1]], shape=(3, 4), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 2  1 16  3]\n",
      " [ 1  4  9 16]\n",
      " [12 12  6  2]], shape=(3, 4), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[2.         1.         1.         3.        ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [1.33333333 0.75       0.66666667 0.5       ]], shape=(3, 4), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[ 2.7182817  2.7182817 54.59815    2.7182817]\n",
      " [ 2.7182817  7.389056  20.085537  54.59815  ]\n",
      " [20.085537  54.59815   20.085537   7.389056 ]], shape=(3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 按元素加减乘除法\n",
    "X = tf.constant([[2,1,4,3],[1,2,3,4],[4,3,2,1]])\n",
    "Y = tf.constant([[1,1,4,1],[1,2,3,4],[3,4,3,2]])\n",
    "\n",
    "print(X+Y)\n",
    "print(X-Y)\n",
    "print(X*Y)\n",
    "print(X/Y)\n",
    "\n",
    "# 按元素做指数运算：\n",
    "# 需要转换类型\n",
    "Y = tf.cast(Y, tf.float32) # Casts a tensor to a new type.\n",
    "print(tf.exp(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "矩阵的运算\n",
    "- matmul：矩阵乘法\n",
    "- tf.transpose：矩阵转置\n",
    "- concatenate连接多个tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 1 3]\n",
      " [1 2 4]\n",
      " [4 3 3]\n",
      " [1 4 2]], shape=(4, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[22 28 28]\n",
      " [19 30 28]\n",
      " [16 20 32]], shape=(3, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[2 1 4 3]\n",
      " [1 2 3 4]\n",
      " [4 3 2 1]\n",
      " [1 1 4 1]\n",
      " [1 2 3 4]\n",
      " [3 4 3 2]], shape=(6, 4), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[2 1 4 3 1 1 4 1]\n",
      " [1 2 3 4 1 2 3 4]\n",
      " [4 3 2 1 3 4 3 2]], shape=(3, 8), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[2 1 4 3 1 1 4 1]\n",
      " [1 2 3 4 1 2 3 4]\n",
      " [4 3 2 1 3 4 3 2]], shape=(3, 8), dtype=int32)\n",
      "tf.Tensor(30, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 按元素加减乘除法\n",
    "X = tf.constant([[2,1,4,3],[1,2,3,4],[4,3,2,1]])\n",
    "Y = tf.constant([[1,1,4,1],[1,2,3,4],[3,4,3,2]])\n",
    "\n",
    "YT = tf.transpose(Y)\n",
    "print(YT)\n",
    "print(tf.matmul(X,YT))\n",
    "\n",
    "# concatenate连接多个tensor\n",
    "\n",
    "# 维度0的长度（ 6 ）为两个输入矩阵在维度0的长度之和（ 3+3 ），\n",
    "print(tf.concat([X,Y],axis=0))\n",
    "#而输出的第二个tensor在维度1的长度（ 8 ）为两个输入矩阵在维度1的长度之和（ 4+4 ）。\n",
    "print(tf.concat([X,Y],axis=1))\n",
    "print(tf.concat([X,Y],axis=-1))\n",
    "\n",
    "#判断式可以得到元素为0或1的新的tensor\n",
    "tf.equal(X,Y)\n",
    "#对tensor中的所有元素求和得到只有一个元素的tensor\n",
    "print(tf.reduce_sum(X))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自动梯度的求解\n",
    "tensorflow2.0提供的GradientTape来自动求梯度\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(3.0)\n",
    "with tf.GradientTape() as g:\n",
    "    g.watch(x)\n",
    "    y = x*x\n",
    "dy_dx = g.gradient(y,x)\n",
    "print(dy_dx)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.0, shape=(), dtype=float32)\n",
      "tf.Tensor(2.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 嵌套梯度\n",
    "x = tf.constant(3.0)\n",
    "with tf.GradientTape() as g:\n",
    "    g.watch(x)\n",
    "    with tf.GradientTape() as gg:\n",
    "        gg.watch(x)\n",
    "        y = x*x\n",
    "    dy_dx = gg.gradient(y,x)\n",
    "\n",
    "d2y_d2x = g.gradient(dy_dx,x)\n",
    "print(dy_dx)\n",
    "print(d2y_d2x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(108.0, shape=(), dtype=float32)\n",
      "tf.Tensor(6.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(3.0)\n",
    "with tf.GradientTape(persistent=True) as g:\n",
    "  g.watch(x)\n",
    "  y = x * x\n",
    "  z = y * y\n",
    "dz_dx = g.gradient(z, x)  # 108.0 (4*x^3 at x = 3)\n",
    "dy_dx = g.gradient(y, x)  # 6.0\n",
    "print(dz_dx)\n",
    "print(dy_dx)\n",
    "del g  # Drop the reference to the tape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### assign 函数的使用\n",
    "使用assign来减少内存开销\n",
    " 如果想避免这个临时内存开销，我们可以使用assign_{运算符全名}函数\n",
    " 这里的X并没有重新开辟内存，以后遇到变量的计算可以考虑使用assign函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "<tf.Variable 'Variable:0' shape=(3,) dtype=int32, numpy=array([ 6,  9, 12])>\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#使用assign来减少内存开销\n",
    "X = tf.Variable([1,2,3])\n",
    "Y = tf.Variable([4,5,6])\n",
    "\n",
    "beforID = id(Y)\n",
    "# Y = X + Y这样的运算，我们也会新开内存，然后将Y指向新内存\n",
    "Y = Y+X\n",
    "print(id(Y)==beforID)\n",
    "\n",
    "\n",
    "Z = tf.Variable(tf.zeros_like(Y))\n",
    "beforID = id(Z)\n",
    "# 还是为X + Y开了临时内存来存储计算结果\n",
    "Z.assign(X+Y)\n",
    "print(id(Z)==beforID)\n",
    "print(Z)\n",
    "\n",
    "#使用assign来减少内存开销\n",
    "# 如果想避免这个临时内存开销，我们可以使用assign_{运算符全名}函数\n",
    "# 这里的X并没有重新开辟内存，以后遇到变量的计算可以考虑使用assign函数\n",
    "beforeIDX = id(X)\n",
    "X.assign_add(Y)\n",
    "print(id(X)==beforeIDX)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
