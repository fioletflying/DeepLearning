{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3612jvsc74a57bd0e17394781024da1f0ed279aab7c6165e80e3acfd2491de02c017c43da5039587",
   "display_name": "Python 3.6.12 64-bit ('tf2': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from  tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import Sequential, layers,optimizers\n",
    "from    PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机种子以及提示信息\n",
    "tf.random.set_seed(22)\n",
    "np.random.seed(22)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "assert tf.__version__.startswith('2.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(imgs,name):\n",
    "    new_img = Image.new('L',(280,280))\n",
    "\n",
    "    index = 0\n",
    "    for i in range(0,280,28):\n",
    "        for j in range(0,280,28):\n",
    "            im = imgs[index]\n",
    "            im = Image.fromarray(im,mode ='L')\n",
    "            new_img.paste(im,(i,j))\n",
    "            index +=1\n",
    "\n",
    "    new_img.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_dim = 20\n",
    "batchsz = 512\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60000, 28, 28) (60000,)\n(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "x_train, x_test = x_train.astype(np.float32) / 255., x_test.astype(np.float32) / 255.\n",
    "# we do not need label\n",
    "train_db = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "train_db = train_db.shuffle(batchsz * 5).batch(batchsz)\n",
    "test_db = tf.data.Dataset.from_tensor_slices(x_test)\n",
    "test_db = test_db.batch(batchsz)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数设置\n",
    "z_dim = 20\n",
    "batch_size = 512\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(VAE,self).__init__()\n",
    "\n",
    "        # Encoder 网络\n",
    "        self.fc1 = layers.Dense(128)\n",
    "        self.fc2 = layers.Dense(z_dim)  #均值\n",
    "        self.fc3 = layers.Dense(z_dim)  #方差\n",
    "\n",
    "        # Decoder 网络\n",
    "        self.fc4 = layers.Dense(128)\n",
    "        self.fc5 = layers.Dense(784)\n",
    "\n",
    "    def encoder(self,x):\n",
    "\n",
    "        h = tf.nn.relu(self.fc1(x))\n",
    "\n",
    "        mu = self.fc2(h)\n",
    "\n",
    "        log_var = self.fc3(h)\n",
    "\n",
    "        return mu,log_var\n",
    "\n",
    "    def decoder(self,z):\n",
    "\n",
    "        out = tf.nn.relu(self.fc4(z))\n",
    "        out = self.fc5(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def reparameterize(self,mu,log_var):\n",
    "\n",
    "        eps = tf.random.normal(log_var.shape)\n",
    "\n",
    "        std = tf.exp(log_var)**0.5\n",
    "\n",
    "        z = mu + std * eps\n",
    "        return z\n",
    "\n",
    "    def call(self,inputs,training=None):\n",
    "        mu,log_var = self.encoder(inputs)\n",
    "\n",
    "        z = self.reparameterize(mu,log_var)\n",
    "\n",
    "        x_hat = self.decoder(z)\n",
    "\n",
    "        return x_hat,mu,log_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"vae_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_21 (Dense)             multiple                  100480    \n_________________________________________________________________\ndense_22 (Dense)             multiple                  2580      \n_________________________________________________________________\ndense_23 (Dense)             multiple                  2580      \n_________________________________________________________________\ndense_24 (Dense)             multiple                  2688      \n_________________________________________________________________\ndense_25 (Dense)             multiple                  101136    \n=================================================================\nTotal params: 209,464\nTrainable params: 209,464\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = VAE()\n",
    "\n",
    "model.build(input_shape=(4,784))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "optimizer = optimizers.Adam(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 0 kl div: 4.994808197021484 rec loss: 0.0013679481344297528\n",
      "0 100 kl div: 0.0012910384684801102 rec loss: 0.0010831286199390888\n",
      "1 0 kl div: 0.0007409519166685641 rec loss: 0.0010349482763558626\n",
      "1 100 kl div: 0.0006935124401934445 rec loss: 0.0009704981930553913\n",
      "2 0 kl div: 0.00042013899656012654 rec loss: 0.000977409421466291\n",
      "2 100 kl div: 0.00024227809626609087 rec loss: 0.000960362667683512\n",
      "3 0 kl div: 0.0004030410200357437 rec loss: 0.0009635186870582402\n",
      "3 100 kl div: 0.0002925911103375256 rec loss: 0.0009743685368448496\n",
      "4 0 kl div: 0.00012343772687017918 rec loss: 0.0009570939000695944\n",
      "4 100 kl div: 0.00015748717123642564 rec loss: 0.0009406720055267215\n",
      "5 0 kl div: 0.00018369726603850722 rec loss: 0.0009612427093088627\n",
      "5 100 kl div: 0.00013153679901733994 rec loss: 0.0009624602389521897\n",
      "6 0 kl div: 0.0001381991314701736 rec loss: 0.0009623814839869738\n",
      "6 100 kl div: 9.958632290363312e-05 rec loss: 0.0009573789429850876\n",
      "7 0 kl div: 8.360372157767415e-05 rec loss: 0.0009592307615093887\n",
      "7 100 kl div: 5.5897864513099194e-05 rec loss: 0.0009574375580996275\n",
      "8 0 kl div: 6.504333578050137e-05 rec loss: 0.0009532053372822702\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-c71aad5b3506>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1071\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1072\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1073\u001b[1;33m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[0;32m   1074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[1;32mD:\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    160\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\u001b[0m in \u001b[0;36m_MatMulGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m   1679\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_MatMulGradAgainstFirstOnly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1680\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mskip_input_indices\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1681\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_MatMulGradAgainstSecondOnly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1682\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1683\u001b[0m     \u001b[1;31m# No gradient skipping, so do the full gradient computation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\u001b[0m in \u001b[0;36m_MatMulGradAgainstSecondOnly\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m   1660\u001b[0m   \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1661\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt_b\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1662\u001b[1;33m     \u001b[0mgrad_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1663\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mt_b\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1664\u001b[0m     \u001b[0mgrad_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   5618\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"MatMul\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5619\u001b[0m         \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"transpose_a\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"transpose_b\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5620\u001b[1;33m         transpose_b)\n\u001b[0m\u001b[0;32m   5621\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5622\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    for step,x in enumerate(train_db):\n",
    "\n",
    "        x = tf.reshape(x,[-1,784])\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            x_rec_logits,mu,log_var = model(x)\n",
    "\n",
    "            rec_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=x,logits=x_rec_logits)\n",
    "\n",
    "            rec_loss = tf.reduce_mean(rec_loss)/x.shape[0]\n",
    "\n",
    "            kl_div = -0.5 * (log_var + 1- mu**2 - tf.exp(log_var))\n",
    "\n",
    "            kl_div = tf.reduce_sum(kl_div)/x.shape[0]\n",
    "\n",
    "            loss = rec_loss + 1. * kl_div\n",
    "\n",
    "\n",
    "        grads = tape.gradient(loss,model.trainable_variables)\n",
    "\n",
    "        optimizer.apply_gradients(zip(grads,model.trainable_variables))\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(epoch, step, 'kl div:', float(kl_div), 'rec loss:', float(rec_loss))\n",
    "\n",
    "    # evaluation\n",
    "    z = tf.random.normal((batchsz, z_dim))\n",
    "    logits = model.decoder(z)\n",
    "    x_hat = tf.sigmoid(logits)\n",
    "    x_hat = tf.reshape(x_hat, [-1, 28, 28]).numpy() *255.\n",
    "    x_hat = x_hat.astype(np.uint8)\n",
    "    save_images(x_hat, 'vae_images/sampled_epoch%d.png'%epoch)\n",
    "\n",
    "    x = next(iter(test_db))\n",
    "    x = tf.reshape(x, [-1, 784])\n",
    "    x_hat_logits, _, _ = model(x)\n",
    "    x_hat = tf.sigmoid(x_hat_logits)\n",
    "    x_hat = tf.reshape(x_hat, [-1, 28, 28]).numpy() *255.\n",
    "    x_hat = x_hat.astype(np.uint8)\n",
    "    save_images(x_hat, 'vae_images/rec_epoch%d.png'%epoch)\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  }
 ]
}